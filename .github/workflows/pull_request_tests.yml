name: Run tests

on: pull_request

jobs:
  pytest:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            python-version: "3.13"
          - os: windows-latest
            python-version: "3.13"

    steps:
    - uses: actions/checkout@v6
      with:
        submodules: true

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}

    #- name: Cache Spark
    #  id: cache-spark
    #  uses: actions/cache@v4
    #  with:
    #    path: spark-4.0.0-bin-hadoop3
    #    key: spark-4.0.0-bin-hadoop3

    - name: Install dependencies (Linux)
      if: runner.os == 'Linux'
      run: |
        python -m venv .venv
        source .venv/bin/activate
        pip install --upgrade pip
        pip install maturin
        pip install -e '.[dev,spark]'

        # Only download if cache miss
        #if [ ! -d "spark-4.0.0-bin-hadoop3" ]; then
        #  echo "Spark cache missed, downloading..."
        #  wget -q https://archive.apache.org/dist/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz
        #  tar -xzf spark-4.0.0-bin-hadoop3.tgz
        #else
        #  echo "Spark restored from cache."
        #fi

        # export SPARK_HOME=$(pwd)/spark-4.0.0-bin-hadoop3
        # ${SPARK_HOME}/sbin/start-thriftserver.sh

    - name: Install dependencies (Windows)
      if: runner.os == 'Windows'
      run: |
        python -m venv .venv
        .venv\Scripts\Activate.ps1
        pip install --upgrade pip
        pip install maturin
        pip install -e '.[dev]'

    - name: Run tests (Linux)
      if: runner.os == 'Linux'
      run: |
        # This does not run the AWS tests.
        # Credentials would need to be configured.
        source .venv/bin/activate
        DSGRID_BACKEND_ENGINE=duckdb python -m pytest -v --disable-warnings --cov=./ --cov-append --cov-report=xml:coverage.xml tests dsgrid/utils/py_expression_eval/tests.py
        # Restart from scratch.
        rm -rf tests/data/registry
        DSGRID_BACKEND_ENGINE=spark python -m pytest -v --disable-warnings --cov=./ --cov-append --cov-report=xml:coverage.xml tests
        DSGRID_BACKEND_ENGINE=spark python -m pytest -v --disable-warnings --cov=./ --cov-append --cov-report=xml:coverage.xml tests/test_spark_functions.py tests/test_spark_utils.py

    - name: Run tests (Windows)
      if: runner.os == 'Windows'
      run: |
        # This does not run the AWS tests.
        # Credentials would need to be configured.
        .venv\Scripts\Activate.ps1
        $env:DSGRID_BACKEND_ENGINE = 'duckdb'
        python -m pytest -v --disable-warnings --cov=./ --cov-append --cov-report=xml:coverage.xml tests dsgrid/utils/py_expression_eval/tests.py

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4.2.0
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        flags: ${{ runner.os }}
        name: ${{ matrix.os }}
        fail_ci_if_error: false
        verbose: true
